import torch
import torch.nn as nn

class SelfAttention(nn.Module):
    def __init__(self, input_dim):
        super(SelfAttention, self).__init__()
        self.query = nn.Linear(input_dim, input_dim)
        self.key = nn.Linear(input_dim, input_dim)
        self.value = nn.Linear(input_dim, input_dim)
        self.softmax = nn.Softmax(dim=2)
        
    def forward(self, x):
        q = self.query(x)
        k = self.key(x)
        v = self.value(x)
        
        scores = torch.matmul(q, k.transpose(1, 2))
        attention_weights = self.softmax(scores)
        
        output = torch.matmul(attention_weights, v)
        
        return output

# Load processed audio data
audio_logmel = "development_audio_logmels.hdf5"
with h5py.File(audio_logmel, "r") as f:
    log_mel_data = f["log_mel"][:]

# Convert to PyTorch tensor
log_mel_tensor = torch.from_numpy(log_mel_data)

# Create self-attention model
input_dim = log_mel_tensor.shape[-1]
self_attention = SelfAttention(input_dim)

# Forward pass
output = self_attention(log_mel_tensor)

print(output.shape)  # Print the shape of the output tensor
